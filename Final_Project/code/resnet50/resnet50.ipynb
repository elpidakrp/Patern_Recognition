{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cnn_resnet50.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6874cw-yOBm"
      },
      "source": [
        "# import libraries\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt \r\n",
        "import random\r\n",
        "import urllib\r\n",
        "import cv2\r\n",
        "\r\n",
        "from keras.models import Sequential\r\n",
        "\r\n",
        "from keras.layers.core import Dense, Dropout, Activation\r\n",
        "from keras.utils import np_utils\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "from keras import optimizers\r\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\r\n",
        "from keras.layers import LeakyReLU\r\n",
        "\r\n",
        "import os\r\n",
        "import PIL\r\n",
        "import PIL.Image\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "import shutil\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import itertools\r\n",
        "\r\n",
        "from keras.layers import Lambda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83NsCfq42CbB",
        "outputId": "f1e90ac0-b481-4aa4-8bc6-289bbc81a945"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fInCI0q2DE6"
      },
      "source": [
        "data_dir = \"/content/drive/My Drive/colab/dataset_bonus\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv48MHQZ2HA3"
      },
      "source": [
        "img_height = 224\r\n",
        "img_width  = 224\r\n",
        "classes    = ['0','1','2','3','4']\r\n",
        "batch_size = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCUGQ6bc2H7u",
        "outputId": "8dd0acdb-cce3-48f4-c837-dc77b5ab9cc6"
      },
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "  data_dir,\r\n",
        "  validation_split=0.3,\r\n",
        "  subset=\"training\",\r\n",
        "  seed=123,\r\n",
        "  image_size=(img_height, img_width),\r\n",
        "  batch_size=batch_size,\r\n",
        "  shuffle=\"true\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 35126 files belonging to 5 classes.\n",
            "Using 24589 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhAx46-o2J52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17da7b96-0c6f-4e2a-f34c-f7bd1181e613"
      },
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "  data_dir,\r\n",
        "  validation_split=0.2,\r\n",
        "  subset=\"validation\",\r\n",
        "  seed=123,\r\n",
        "  image_size=(img_height, img_width),\r\n",
        "  batch_size=batch_size,\r\n",
        "  shuffle=\"true\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 35126 files belonging to 5 classes.\n",
            "Using 7025 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTAtrymR2OGm"
      },
      "source": [
        "num_classes = 5\r\n",
        "\r\n",
        "min=-1\r\n",
        "max=1\r\n",
        "\r\n",
        "filepath = \"weights.best.hdf5\"\r\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, \r\n",
        "                             save_best_only=True, save_weights_only=True, \r\n",
        "                             mode='auto', save_freq='epoch')\r\n",
        "\r\n",
        "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=50, \r\n",
        "                      verbose=1, mode='auto')\r\n",
        "\r\n",
        "\r\n",
        "from keras.applications.resnet50 import ResNet50\r\n",
        "model = ResNet50()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idOXhMTy2O-c"
      },
      "source": [
        "model.compile(\r\n",
        "  optimizer='adam',\r\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSoWfH2O2Qzo"
      },
      "source": [
        "history = model.fit(\r\n",
        "  train_ds,\r\n",
        "  validation_data=val_ds,\r\n",
        "  epochs=500,\r\n",
        "  callbacks=[checkpoint, early]\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZneQUr62WBu"
      },
      "source": [
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "  data_dir,\r\n",
        "  validation_split=0.1,\r\n",
        "  subset=\"validation\",\r\n",
        "  seed=123, \r\n",
        "  image_size=(img_height, img_width),\r\n",
        "  batch_size=batch_size,\r\n",
        "  shuffle=\"true\",\r\n",
        "  color_mode=\"grayscale\")\r\n",
        "\r\n",
        "model.load_weights(\"weights.best.hdf5\")\r\n",
        "score = model.evaluate(test_ds)\r\n",
        "print('Test score: ', score[0])\r\n",
        "print('Test accuracy: ', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-gz3nLnO-us"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGece2yt89M0"
      },
      "source": [
        "from sklearn import metrics\r\n",
        "from sklearn.metrics import plot_confusion_matrix\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "predictions = np.array([])\r\n",
        "true_labels =  np.array([])\r\n",
        "for x, y in test_ds:\r\n",
        "  predictions = np.concatenate([predictions, model.predict_classes(x)])\r\n",
        "  true_labels = np.concatenate([true_labels, y.numpy()])\r\n",
        "\r\n",
        "precisions, recall, f1_score, samples_per_class = metrics.precision_recall_fscore_support(true_labels, predictions,labels = [0,1,2,3,4,5,6,7,8,9])\r\n",
        "confusion_matrix = metrics.confusion_matrix(true_labels, predictions)\r\n",
        "print('Precision :',precisions,'\\nRecall :',recall,'\\nF1_Score :',f1_score,'\\nSamples per class :',samples_per_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhk36Jsd9Lr4"
      },
      "source": [
        "target_names=['0','1','2','3','4','5','6','7','8','9']\r\n",
        "# plot_confusion_matrix(confusion_matrix, target_names, title='Confusion matrix', cmap=None, normalize=None)\r\n",
        "accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix).astype('float')\r\n",
        "misclass = 1 - accuracy\r\n",
        "cmap = plt.get_cmap('Blues')\r\n",
        "\r\n",
        "plt.figure(figsize=(8, 6))\r\n",
        "plt.imshow(confusion_matrix, interpolation='nearest', cmap=cmap)\r\n",
        "plt.title('Confusion Matrix')\r\n",
        "plt.colorbar()\r\n",
        "\r\n",
        "tick_marks = np.arange(len(target_names))\r\n",
        "plt.xticks(tick_marks, target_names, rotation=45)\r\n",
        "plt.yticks(tick_marks, target_names)\r\n",
        "\r\n",
        "thresh = confusion_matrix.max() / 2\r\n",
        "for i, j in itertools.product(range(confusion_matrix.shape[0]), range(confusion_matrix.shape[1])):\r\n",
        "    plt.text(j, i, \"{:,}\".format(confusion_matrix[i, j]),\r\n",
        "              horizontalalignment=\"center\",\r\n",
        "              color=\"white\" if confusion_matrix[i, j] > thresh else \"black\")\r\n",
        "\r\n",
        "plt.tight_layout()\r\n",
        "plt.ylabel('Labels')\r\n",
        "plt.xlabel('Predicted Labels\\naccuracy: {:0.4f} - misclass: {:0.4f}'.format(accuracy, misclass))\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxhkvyrB9VNg"
      },
      "source": [
        "epochs = range(0,len(history.history['loss']))\r\n",
        "loss_train = history.history['loss']\r\n",
        "loss_val   = history.history['val_loss']\r\n",
        "plt.plot(epochs, loss_train, 'g', label='Training loss')\r\n",
        "plt.plot(epochs, loss_val, 'r', label='Validation loss')\r\n",
        "plt.title('Training/Validation losses')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKYYeUBmR7Jn"
      },
      "source": [
        "epochs = range(0,len(history.history['accuracy']))\r\n",
        "acc_train = history.history['accuracy']\r\n",
        "acc_val   = history.history['val_accuracy']\r\n",
        "plt.plot(epochs, acc_train, 'g', label='Training accuracy')\r\n",
        "plt.plot(epochs, acc_val, 'r', label='Validation accuracy')\r\n",
        "plt.title('Training/Validation accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}